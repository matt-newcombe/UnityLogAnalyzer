/**
 * Timeline Builder
 * Handles complex timeline construction logic for log visualization
 */

class TimelineBuilder {
    constructor(db, logId) {
        this.db = db;
        this.logId = logId;
    }

    /**
     * Build timeline data for visualization
     */
    async build() {
        const buildStartTime = performance.now();

        // Get metadata - direct indexed lookup (should be very fast)
        // For already-parsed logs, metadata should exist immediately
        const metadataStart = performance.now();

        // Direct query - IndexedDB may need to initialize on first access after opening
        // This can be slow (1+ seconds) but subsequent queries are fast
        const queryStart = performance.now();
        let metadata = await this.db.log_metadata.get(this.logId);
        const queryTime = performance.now() - queryStart;

        metadata = await this.db.log_metadata.get(this.logId);

        const metadataTime = performance.now() - metadataStart;

        let firstTimestamp = null;
        let lastTimestamp = null;
        let useStoredTimestamps = false;

        if (metadata && metadata.start_timestamp && metadata.end_timestamp) {
            // Use stored timestamps from parsing - these are the actual first and last timestamps in the log
            firstTimestamp = metadata.start_timestamp;
            lastTimestamp = metadata.end_timestamp;
            useStoredTimestamps = true;
        }

        // Get imports - use index for sorted query (much faster than loading all and sorting in JS)
        const importsStart = performance.now();
        const imports = await this.db.asset_imports
            .where('log_id').equals(this.logId)
            .sortBy('line_number');
        const importsTime = performance.now() - importsStart;

        // Get operations - use index for sorted query
        const operationsStart = performance.now();
        const operations = await this.db.operations
            .where('log_id').equals(this.logId)
            .sortBy('line_number');
        const operationsTime = performance.now() - operationsStart;

        // Get cache server download blocks - use index for sorted query
        const cacheBlocksStart = performance.now();
        const cacheServerBlocks = await this.db.cache_server_download_blocks
            .where('log_id').equals(this.logId)
            .sortBy('start_timestamp');
        const cacheBlocksTime = performance.now() - cacheBlocksStart;

        // Get worker thread phases - use index for sorted query
        const workerPhasesStart = performance.now();
        const workerPhases = await this.db.worker_thread_phases
            .where('log_id').equals(this.logId)
            .sortBy('start_timestamp');
        const workerPhasesTime = performance.now() - workerPhasesStart;

        // Get worker imports - these are asset_imports with non-null worker_thread_id
        const workerImportsStart = performance.now();
        const workerImports = await this.db.asset_imports
            .where('log_id').equals(this.logId)
            .filter(imp => imp.worker_thread_id !== null && imp.worker_thread_id !== undefined)
            .sortBy('line_number');
        const workerImportsTime = performance.now() - workerImportsStart;

        // If we don't have stored timestamps in metadata, try to extract from imports, operations, and worker imports
        // Fallback to arbitrary defaults if no timestamps found
        if (!useStoredTimestamps) {
            // Helper to get end timestamp from start + duration
            const getEndTimestamp = (startTs, durationMs) => {
                if (!startTs) return null;
                if (durationMs) {
                    const startTime = new Date(startTs).getTime();
                    return new Date(startTime + durationMs).toISOString();
                }
                return startTs;
            };

            // Check imports for timestamps
            imports.forEach(imp => {
                if (imp.start_timestamp) {
                    if (!firstTimestamp || imp.start_timestamp < firstTimestamp) {
                        firstTimestamp = imp.start_timestamp;
                    }
                    const endTs = imp.end_timestamp || getEndTimestamp(imp.start_timestamp, imp.import_time_ms);
                    if (endTs && (!lastTimestamp || endTs > lastTimestamp)) {
                        lastTimestamp = endTs;
                    }
                }
            });

            // Check operations for timestamps
            operations.forEach(op => {
                if (op.start_timestamp) {
                    if (!firstTimestamp || op.start_timestamp < firstTimestamp) {
                        firstTimestamp = op.start_timestamp;
                    }
                }
                const endTs = op.end_timestamp || getEndTimestamp(op.start_timestamp, op.duration_ms);
                if (endTs && (!lastTimestamp || endTs > lastTimestamp)) {
                    lastTimestamp = endTs;
                }
            });

            // Check cache server blocks for timestamps
            cacheServerBlocks.forEach(block => {
                if (block.start_timestamp) {
                    if (!firstTimestamp || block.start_timestamp < firstTimestamp) {
                        firstTimestamp = block.start_timestamp;
                    }
                }
                const endTs = block.end_timestamp;
                if (endTs && (!lastTimestamp || endTs > lastTimestamp)) {
                    lastTimestamp = endTs;
                }
            });

            // Check worker imports for timestamps
            // This is critical for non-timestamped logs where operations with durations
            // calculate start_timestamp by subtracting duration from current time,
            // which can be before the epoch (1999-12-31, etc.)
            workerImports.forEach(imp => {
                if (imp.start_timestamp) {
                    if (!firstTimestamp || imp.start_timestamp < firstTimestamp) {
                        firstTimestamp = imp.start_timestamp;
                    }
                    const endTs = imp.end_timestamp || getEndTimestamp(imp.start_timestamp, imp.duration_ms || imp.import_time_ms);
                    if (endTs && (!lastTimestamp || endTs > lastTimestamp)) {
                        lastTimestamp = endTs;
                    }
                }
            });

            // Fallback to arbitrary defaults if no timestamps found
            if (!firstTimestamp || !lastTimestamp) {
                const now = new Date();
                if (!firstTimestamp) {
                    firstTimestamp = new Date(now.getTime() - 3600000).toISOString();
                }
                if (!lastTimestamp) {
                    lastTimestamp = now.toISOString();
                }
            }
        }

        // Build timeline segments - group by category properly
        const segments = [];

        // Merge imports and operations by line number to get actual sequence
        // Since both arrays are already sorted by line_number, we can merge them efficiently
        const mergeStart = performance.now();
        const allEvents = [];

        let importIndex = 0;
        let operationIndex = 0;

        // Merge two sorted arrays (imports and operations) by line_number
        while (importIndex < imports.length || operationIndex < operations.length) {
            const importLineNum = importIndex < imports.length ? (imports[importIndex].line_number || 0) : Infinity;
            const operationLineNum = operationIndex < operations.length ? (operations[operationIndex].line_number || 0) : Infinity;

            if (importLineNum <= operationLineNum) {
                // Process import
                const imp = imports[importIndex++];

                // Skip worker thread imports - they will be shown in worker lanes
                if (imp.worker_thread_id !== null && imp.worker_thread_id !== undefined) {
                    continue;
                }

                // Use stored timestamps if available (from parsing)
                let startTimestamp = imp.start_timestamp;
                let endTimestamp = imp.end_timestamp;

                // If we have start_timestamp but no end_timestamp, calculate from duration
                if (startTimestamp && !endTimestamp && imp.import_time_ms) {
                    const startTime = new Date(startTimestamp).getTime();
                    endTimestamp = new Date(startTime + imp.import_time_ms).toISOString();
                }

                // Use duration_ms (wall time if available, else import_time_ms)
                const durationMs = imp.duration_ms || 0;

                allEvents.push({
                    line_number: imp.line_number || 0,
                    type: 'import',
                    time_ms: durationMs,
                    name: imp.asset_name || '',
                    asset_type: imp.asset_type || '',
                    category: imp.asset_category || 'Other',
                    start_timestamp: startTimestamp,
                    end_timestamp: endTimestamp
                });
            } else {
                // Process operation
                const op = operations[operationIndex++];
                // Use stored timestamps from database
                let startTimestamp = op.start_timestamp;
                let endTimestamp = op.end_timestamp;

                // If we have start_timestamp but no end_timestamp, calculate from duration
                if (startTimestamp && !endTimestamp && op.duration_ms) {
                    const startTime = new Date(startTimestamp).getTime();
                    endTimestamp = new Date(startTime + op.duration_ms).toISOString();
                }

                // Calculate duration from timestamps if available, otherwise use duration_ms
                let timeMs = op.duration_ms || 0;
                if (startTimestamp && endTimestamp) {
                    const startTime = new Date(startTimestamp).getTime();
                    const endTime = new Date(endTimestamp).getTime();
                    timeMs = endTime - startTime;
                }

                allEvents.push({
                    line_number: op.line_number || 0,
                    type: 'operation',
                    time_ms: timeMs,
                    operation_type: op.process_type || '',
                    operation_name: op.process_name || '',
                    start_timestamp: startTimestamp,
                    end_timestamp: endTimestamp
                });
            }
        }
        const mergeTime = performance.now() - mergeStart;

        // Determine if we have timestamps available for positioning
        // For both timestamped and non-timestamped logs, we use timestamp-based positioning
        // if we have valid start/end timestamps in metadata (calculated or real).
        // The metadata.timestampsEnabled flag tells us if timestamps are real (from -timestamps flag)
        // or calculated (from logCurrentTime + durations), but both can be used for positioning.
        const hasTimestamps = useStoredTimestamps && firstTimestamp && lastTimestamp;

        // Calculate total log duration in milliseconds
        // For timestamped logs: use wall time from first to last timestamp
        // For non-timestamped logs: will be calculated after segments are built (from cumulative time)
        let totalTimeMs = 0;
        if (hasTimestamps && firstTimestamp && lastTimestamp) {
            // Use timestamp-based duration (wall time)
            const startTime = new Date(firstTimestamp).getTime();
            const endTime = new Date(lastTimestamp).getTime();
            totalTimeMs = endTime - startTime;
        }
        // For non-timestamped logs, totalTimeMs will be calculated from final cumulative time

        // Group consecutive imports into chunks by category
        // Key: Category changes always start a new chunk, even if gap is small
        // Also group logical operations like initial compiles, sprite packs, etc.
        const chunkingStart = performance.now();
        const importChunks = [];
        let currentChunk = [];
        const operationsInSequence = [];

        // Helper to calculate chunk time for timeline visualization
        // Use timestamp-based duration to show wall time (includes file I/O and gaps)
        // This matches the user requirement: "timeline chunks should always be the width 
        // of their recorded time, this should now be the time started and ended in the 
        // time stamps, rather than the explicit completion time in the log itself"
        const calculateChunkTime = (chunk) => {
            if (chunk.length === 0) return 0;

            const firstEvent = chunk[0];
            const lastEvent = chunk[chunk.length - 1];

            // Use timestamps for timeline visualization (shows wall time including gaps/file I/O)
            if (firstEvent.start_timestamp && lastEvent.end_timestamp) {
                const startTime = new Date(firstEvent.start_timestamp).getTime();
                const endTime = new Date(lastEvent.end_timestamp).getTime();
                const wallTime = endTime - startTime;
                // Use wall time if it's reasonable (at least as long as the sum of durations)
                const sumDurations = chunk.reduce((sum, e) => sum + (e.time_ms || 0), 0);
                return Math.max(wallTime, sumDurations);
            }

            // Fallback to sum of durations if timestamps unavailable
            // This is the actual work time for the chunk
            return chunk.reduce((sum, e) => sum + (e.time_ms || 0), 0);
        };

        // Helper to calculate actual import time (sum of durations, excluding gaps)
        // This is used for summary statistics to match the category widget
        const calculateActualImportTime = (chunk) => {
            if (chunk.length === 0) return 0;
            return chunk.reduce((sum, e) => sum + (e.time_ms || 0), 0);
        };

        allEvents.forEach((event, idx) => {
            if (event.type === 'import') {
                if (currentChunk.length === 0) {
                    // Start new chunk
                    currentChunk.push(event);
                } else {
                    // Check gap and category
                    const prevLine = currentChunk[currentChunk.length - 1].line_number;
                    const prevCategory = currentChunk[currentChunk.length - 1].category || 'Other';
                    const currentCategory = event.category || 'Other';
                    const gap = event.line_number - prevLine;

                    // Category changed = always start new chunk (even if gap is small)
                    // Same category = allow larger gaps (up to 50 lines for worker thread imports)
                    if (currentCategory !== prevCategory) {
                        // Category changed - finish current chunk, start new one
                        this._finishChunk(currentChunk, importChunks, calculateChunkTime, calculateActualImportTime);
                        currentChunk = [event];
                    } else if (gap <= 50) {
                        // Same category and reasonable gap - continue chunk
                        currentChunk.push(event);
                    } else {
                        // Same category but very large gap - start new chunk
                        this._finishChunk(currentChunk, importChunks, calculateChunkTime, calculateActualImportTime);
                        currentChunk = [event];
                    }
                }
            } else if (event.type === 'operation') {
                // If there's a current chunk, finish it before the operation
                if (currentChunk.length > 0) {
                    this._finishChunk(currentChunk, importChunks, calculateChunkTime, calculateActualImportTime);
                    currentChunk = [];
                }
                // Store operations to insert at correct positions
                operationsInSequence.push(event);
            }
        });

        // Finish last chunk
        if (currentChunk.length > 0) {
            this._finishChunk(currentChunk, importChunks, calculateChunkTime, calculateActualImportTime);
        }

        // Merge import chunks and operations by line number for correct sequence
        const timelineEvents = [];

        // Add import chunks
        importChunks.forEach(chunk => {
            timelineEvents.push({
                line_number: chunk.start_line,
                type: 'import_chunk',
                data: chunk
            });
        });

        // Add operations (deduplicate by line_number and operation_type to avoid duplicates)
        const seenOperations = new Set();
        operationsInSequence.forEach(op => {
            const key = `${op.line_number}_${op.process_type}_${op.process_name}`;
            if (!seenOperations.has(key)) {
                seenOperations.add(key);
                timelineEvents.push({
                    line_number: op.line_number,
                    type: 'operation',
                    data: op
                });
            }
        });

        // Add cache server download blocks
        cacheServerBlocks.forEach(block => {
            timelineEvents.push({
                line_number: block.line_number,
                type: 'cache_server_block',
                data: block
            });
        });

        // Sort by line number
        timelineEvents.sort((a, b) => (a.line_number || 0) - (b.line_number || 0));

        // Helper function to format time (matches formatTime from dashboard)
        const formatTime = (seconds) => {
            if (seconds >= 3600) {
                const hours = Math.floor(seconds / 3600);
                const mins = Math.floor((seconds % 3600) / 60);
                return `${hours}h ${mins}m`;
            } else if (seconds >= 60) {
                const minutes = Math.floor(seconds / 60);
                const secs = Math.floor(seconds % 60);
                return `${minutes}m ${secs}s`;
            }
            return seconds.toFixed(2) + 's';
        };

        // Build timeline segments
        // Use different positioning strategies based on whether we have timestamps:
        // - With timestamps: Use actual wall time from timestamps (shows real-time gaps, I/O, etc.)
        // - Without timestamps: Use sequential positioning based on cumulative durations (shows work time)
        const startTimeOffset = hasTimestamps && firstTimestamp ? new Date(firstTimestamp).getTime() : 0;

        // For non-timestamped logs, track cumulative time for sequential positioning
        // Events are already sorted by line_number, so this creates a sequential timeline
        let cumulativeTime = 0;

        timelineEvents.forEach(event => {
            if (event.type === 'import_chunk') {
                const chunk = event.data;

                // Calculate start_time based on available data
                let startTime = 0;
                if (hasTimestamps && chunk.start_timestamp) {
                    // Use actual timestamp (timestamped log)
                    startTime = new Date(chunk.start_timestamp).getTime() - startTimeOffset;
                } else if (hasTimestamps && totalTimeMs > 0 && firstTimestamp && chunk.start_line && metadata && metadata.total_lines) {
                    // Estimate from line number proportion (timestamped log but chunk missing timestamp)
                    // Only do this if we have a valid totalTimeMs
                    const totalLines = metadata.total_lines;
                    if (totalLines > 0) {
                        const lineProportion = chunk.start_line / totalLines;
                        startTime = totalTimeMs * lineProportion;
                    } else {
                        // Can't estimate - position at 0 (will be sorted later)
                        startTime = 0;
                    }
                } else {
                    // No timestamps or can't use timestamp-based positioning: use sequential positioning
                    startTime = cumulativeTime;
                    cumulativeTime += chunk.time_ms || 0;
                }

                // Only add segment if it has a valid duration (greater than 0)
                // This prevents empty segments from appearing, but we should still log them for debugging
                if (chunk.time_ms > 0) {
                    // Use wall time for display (time span from first to last import)
                    const timeSeconds = chunk.time_ms / 1000;
                    segments.push({
                        phase: 'AssetImports',
                        start_time: startTime,
                        duration_ms: chunk.time_ms, // Wall time for positioning and display
                        actual_import_time_ms: chunk.actual_import_time_ms || 0, // Keep for reference
                        color: '#4CAF50',
                        category: chunk.category,
                        description: `Asset imports - ${chunk.count} assets (${formatTime(timeSeconds)})`, // Show wall time
                        asset_count: chunk.count,
                        line_number: chunk.start_line
                    });
                } else {
                    console.warn('[Timeline] Skipping chunk with zero duration:', {
                        category: chunk.category,
                        count: chunk.count,
                        start_line: chunk.start_line,
                        end_line: chunk.end_line,
                        actual_import_time_ms: chunk.actual_import_time_ms
                    });
                }
            } else if (event.type === 'operation') {
                const op = event.data;
                const timeSeconds = (op.time_ms || 0) / 1000;

                // Calculate start_time based on available data
                let startTime = 0;
                if (hasTimestamps && op.start_timestamp) {
                    // Use actual timestamp (timestamped log)
                    // Convert timestamp to milliseconds since epoch, then subtract the offset
                    // This gives us the time relative to the start of the log (normalized to 0)
                    const opStartTime = new Date(op.start_timestamp).getTime();
                    if (!isNaN(opStartTime) && startTimeOffset > 0) {
                        startTime = opStartTime - startTimeOffset;
                    } else {
                        console.warn('[Timeline] Invalid start_timestamp for operation:', {
                            line_number: op.line_number,
                            operation_type: op.process_type,
                            start_timestamp: op.start_timestamp,
                            opStartTime: opStartTime,
                            startTimeOffset: startTimeOffset
                        });
                        // Fall back to line number estimation
                        if (totalTimeMs > 0 && op.line_number && metadata && metadata.total_lines) {
                            const totalLines = metadata.total_lines;
                            if (totalLines > 0) {
                                const lineProportion = op.line_number / totalLines;
                                startTime = totalTimeMs * lineProportion;
                            }
                        }
                    }
                } else if (hasTimestamps && totalTimeMs > 0 && firstTimestamp && op.line_number && metadata && metadata.total_lines) {
                    // Estimate from line number proportion (timestamped log but operation missing timestamp)
                    // Only do this if we have a valid totalTimeMs
                    const totalLines = metadata.total_lines;
                    if (totalLines > 0) {
                        const lineProportion = op.line_number / totalLines;
                        startTime = totalTimeMs * lineProportion;
                    } else {
                        // Can't estimate - position at 0 (will be sorted later)
                        startTime = 0;
                    }
                } else {
                    // No timestamps or can't use timestamp-based positioning: use sequential positioning
                    startTime = cumulativeTime;
                    cumulativeTime += op.time_ms || op.duration_ms || 0;
                }

                // Determine phase based on operation type
                let phase = 'Operation';
                if (op.process_type === 'Script Compilation') {
                    phase = 'CompileScripts';
                }

                // Calculate duration from timestamps if available
                // Use wall-to-wall time from timestamps for accurate duration
                let durationMs = op.time_ms || op.duration_ms || 0;
                if (op.start_timestamp && op.end_timestamp) {
                    const startTimeMs = new Date(op.start_timestamp).getTime();
                    const endTimeMs = new Date(op.end_timestamp).getTime();
                    if (!isNaN(startTimeMs) && !isNaN(endTimeMs)) {
                        durationMs = endTimeMs - startTimeMs;
                    }
                }

                segments.push({
                    phase: phase,
                    start_time: startTime,
                    duration_ms: durationMs,
                    color: op.process_type === 'Script Compilation' ? '#9966FF' : '#FF5722',
                    description: `${op.process_type}: ${op.process_name} (${formatTime(durationMs / 1000)})`,
                    operation_type: op.process_type,
                    operation_name: op.process_name,
                    line_number: op.line_number
                });
            } else if (event.type === 'cache_server_block') {
                const block = event.data;
                const durationMs = block.duration_ms || 0;

                // Calculate start_time based on available data
                // Use the same logic as operations for consistency
                let startTime = 0;
                if (hasTimestamps && block.start_timestamp) {
                    // Use actual timestamp (timestamped log)
                    // Convert timestamp to milliseconds since epoch, then subtract the offset
                    // This gives us the time relative to the start of the log (normalized to 0)
                    const blockStartTime = new Date(block.start_timestamp).getTime();
                    if (!isNaN(blockStartTime) && startTimeOffset > 0) {
                        startTime = blockStartTime - startTimeOffset;
                    } else {
                        console.warn('[Timeline] Invalid timestamp for cache server block:', {
                            line_number: block.line_number,
                            start_timestamp: block.start_timestamp,
                            blockStartTime: blockStartTime,
                            startTimeOffset: startTimeOffset
                        });
                        // Fall back to line number estimation
                        if (totalTimeMs > 0 && block.line_number && metadata && metadata.total_lines) {
                            const totalLines = metadata.total_lines;
                            if (totalLines > 0) {
                                const lineProportion = block.line_number / totalLines;
                                startTime = totalTimeMs * lineProportion;
                            }
                        }
                    }
                } else if (hasTimestamps && totalTimeMs > 0 && firstTimestamp && block.line_number && metadata && metadata.total_lines) {
                    // Estimate from line number proportion (timestamped log but block missing timestamp)
                    // Only do this if we have a valid totalTimeMs
                    const totalLines = metadata.total_lines;
                    if (totalLines > 0) {
                        const lineProportion = block.line_number / totalLines;
                        startTime = totalTimeMs * lineProportion;
                    } else {
                        // Can't estimate - position at 0 (will be sorted later)
                        startTime = 0;
                    }
                } else {
                    // Sequential positioning for non-timestamped logs
                    startTime = cumulativeTime;
                    cumulativeTime += durationMs;
                }

                segments.push({
                    phase: 'CacheServerDownload',
                    start_time: startTime,
                    duration_ms: durationMs,
                    color: '#9C27B0', // Purple color for cache server downloads
                    description: `Cache Server Download: ${block.num_assets_downloaded}/${block.num_assets_requested} assets (${formatTime(durationMs / 1000)})`,
                    line_number: block.line_number
                });
            }
        });

        // Sort segments by start_time to ensure correct order
        segments.sort((a, b) => a.start_time - b.start_time);
        const cacheServerBlockSegments = segments.filter(s => s.phase === 'CacheServerDownload').length;
        const chunkingTime = performance.now() - chunkingStart;

        // Calculate actual asset import time from database (not from timeline segments)
        // This ensures consistency with the category widget which uses import_time_ms
        const processingStart = performance.now();
        const actualAssetImportTime = imports.reduce((sum, imp) => sum + (imp.import_time_ms || 0), 0);

        // Ensure totalTimeMs is valid
        let finalTotalTimeMs = totalTimeMs;

        // Check if any segment extends beyond the calculated total time
        // This handles cases where:
        // 1. We have timestamps but some operations (without timestamps) are estimated to end later
        // 2. We have timestamps but the last operation's duration extends beyond the last log timestamp
        if (segments.length > 0) {
            const lastSegment = segments[segments.length - 1];
            const lastSegmentEnd = lastSegment.start_time + lastSegment.duration_ms;
            if (lastSegmentEnd > finalTotalTimeMs) {
                finalTotalTimeMs = lastSegmentEnd;
            }
        }

        if (finalTotalTimeMs === 0) {
            // No timestamps and no segments? Fallback logic...

            // Also calculate from sum of all import/operation durations as a sanity check
            const allDurations = [
                ...imports.map(imp => imp.import_time_ms || 0),
                ...operations.map(op => op.duration_ms || op.time_ms || 0)
            ];
            const sumDurations = allDurations.reduce((sum, d) => sum + d, 0);

            // Use the larger of: last segment end time, or sum of all durations
            // This ensures we capture the full timeline even if segments are positioned incorrectly
            if (sumDurations > finalTotalTimeMs) {
                finalTotalTimeMs = sumDurations;
            }

            // If still zero, use line number estimation
            if (finalTotalTimeMs === 0 && (imports.length > 0 || operations.length > 0)) {
                const maxLine = Math.max(
                    ...imports.map(i => i.line_number || 0),
                    ...operations.map(o => o.line_number || 0)
                );
                const minLine = Math.min(
                    ...imports.filter(i => i.line_number).map(i => i.line_number),
                    ...operations.filter(o => o.line_number).map(o => o.line_number)
                );
                finalTotalTimeMs = Math.max(1000, (maxLine - minLine) * 1);
            }

            // Final fallback: ensure we never return 0 (minimum 1 second)
            // This prevents division by zero errors in the timeline visualization
            if (finalTotalTimeMs === 0) {
                console.warn('[Timeline] No timeline data available, using minimum duration');
                finalTotalTimeMs = 1000; // 1 second minimum
            }
        }

        // Debug: Check category distribution in segments
        const categoryCounts = {};
        segments.forEach(s => {
            const cat = s.category || 'N/A';
            categoryCounts[cat] = (categoryCounts[cat] || 0) + 1;
        });

        // Debug: Check category distribution in imports
        const importCategoryCounts = {};
        imports.forEach(imp => {
            const cat = imp.asset_category || 'Other';
            importCategoryCounts[cat] = (importCategoryCounts[cat] || 0) + 1;
        });

        const processingTime = performance.now() - processingStart;
        const totalBuildTime = performance.now() - buildStartTime;

        // Build worker thread timeline data
        console.log('[Timeline] Building worker thread timeline from', imports.length, 'total imports');
        const workerThreadData = await this._buildWorkerThreadTimeline(imports, workerPhases, firstTimestamp, totalTimeMs, startTimeOffset);
        console.log('[Timeline] Worker thread data:', workerThreadData);

        return {
            total_time_ms: finalTotalTimeMs,
            segments: segments,
            summary: {
                asset_import_time_ms: actualAssetImportTime, // Use actual import times from database
                total_imports: imports.length
            },
            first_timestamp: firstTimestamp,
            last_timestamp: lastTimestamp,
            worker_threads: workerThreadData
        };
    }

    /**
     * Build worker thread timeline data
     * @private
     */
    async _buildWorkerThreadTimeline(allImports, workerPhases, firstTimestamp, totalTimeMs, startTimeOffset) {
        // Filter worker thread imports
        const workerImports = allImports.filter(imp =>
            imp.worker_thread_id !== null && imp.worker_thread_id !== undefined
        );

        console.log('[Timeline] Worker imports found:', workerImports.length, 'out of', allImports.length);
        console.log('[Timeline] Worker phases found:', workerPhases.length);

        if (workerImports.length > 0) {
            console.log('[Timeline] Sample worker import:', workerImports[0]);
            // Debug: Check timestamp distribution and overlap
            const timestampStats = {};
            workerImports.slice(0, 20).forEach(imp => {
                const workerId = imp.worker_thread_id;
                if (!timestampStats[workerId]) {
                    timestampStats[workerId] = {
                        withTimestamp: 0,
                        withoutTimestamp: 0,
                        uniqueTimestamps: new Set(),
                        samples: []
                    };
                }
                if (imp.start_timestamp) {
                    timestampStats[workerId].withTimestamp++;
                    timestampStats[workerId].uniqueTimestamps.add(imp.start_timestamp);
                    timestampStats[workerId].samples.push({
                        start: imp.start_timestamp,
                        end: imp.end_timestamp,
                        duration: imp.duration_ms,
                        line: imp.line_number
                    });
                } else {
                    timestampStats[workerId].withoutTimestamp++;
                }
            });
            console.log('[Timeline] Worker timestamp stats (first 20):', timestampStats);

            // Check for parallel execution opportunities
            const workerIds = Object.keys(timestampStats);
            if (workerIds.length > 1) {
                console.log('[Timeline] Checking for parallel execution between workers...');
                workerIds.forEach(workerId1 => {
                    workerIds.forEach(workerId2 => {
                        if (workerId1 < workerId2) {
                            const samples1 = timestampStats[workerId1].samples || [];
                            const samples2 = timestampStats[workerId2].samples || [];
                            if (samples1.length > 0 && samples2.length > 0) {
                                const s1 = samples1[0];
                                const s2 = samples2[0];
                                const s1Start = new Date(s1.start).getTime();
                                const s1End = s1.end ? new Date(s1.end).getTime() : s1Start + (s1.duration || 0);
                                const s2Start = new Date(s2.start).getTime();
                                const s2End = s2.end ? new Date(s2.end).getTime() : s2Start + (s2.duration || 0);

                                // Check if they overlap
                                const overlap = !(s1End < s2Start || s2End < s1Start);
                                if (overlap) {
                                    console.log(`[Timeline] Workers ${workerId1} and ${workerId2} should overlap:`, {
                                        worker1: { start: s1.start, end: s1.end || 'calculated' },
                                        worker2: { start: s2.start, end: s2.end || 'calculated' }
                                    });
                                }
                            }
                        }
                    });
                });
            }
        }

        if (workerImports.length === 0) {
            return {};
        }

        // Group by worker_thread_id
        const workerThreads = {};
        workerImports.forEach(imp => {
            const workerId = imp.worker_thread_id;
            if (!workerThreads[workerId]) {
                workerThreads[workerId] = [];
            }
            workerThreads[workerId].push(imp);
        });

        // Build segments for each worker thread
        const workerTimelines = {};
        
        // For non-timestamped logs, we need to position worker imports based on their line numbers
        // relative to the total timeline, similar to how main-thread events are positioned
        const hasTimestamps = firstTimestamp && totalTimeMs > 0;
        
        Object.keys(workerThreads).forEach(workerId => {
            const imports = workerThreads[workerId];

            // Sort by line_number first to ensure correct order (line number reflects actual log order)
            imports.sort((a, b) => (a.line_number || 0) - (b.line_number || 0));

            const segments = [];
            let logicalEndTime = 0; // Track logical end time for sequential positioning (fallback only)

            imports.forEach(imp => {
                // Calculate start time relative to timeline start
                let startTime = 0;
                const durationMs = imp.duration_ms || imp.import_time_ms || 0;

                if (imp.start_timestamp && hasTimestamps) {
                    // Use actual timestamp - trust it to show correct timing (including parallel execution)
                    const impStartTime = new Date(imp.start_timestamp).getTime();
                    startTime = impStartTime - startTimeOffset;

                    // Update logical end time based on actual end timestamp if available
                    // This is only used as a fallback for operations without timestamps
                    if (imp.end_timestamp) {
                        const impEndTime = new Date(imp.end_timestamp).getTime();
                        logicalEndTime = Math.max(logicalEndTime, impEndTime - startTimeOffset);
                    } else {
                        // No end timestamp, calculate from start + duration
                        logicalEndTime = Math.max(logicalEndTime, startTime + durationMs);
                    }
                } else {
                    // No timestamp available - use sequential positioning based on logical time
                    startTime = logicalEndTime;
                    logicalEndTime = startTime + durationMs;
                }

                segments.push({
                    phase: 'WorkerImport',
                    start_time: startTime,
                    duration_ms: durationMs,
                    color: this._getWorkerColor(workerId),
                    category: imp.asset_category || 'Other',
                    description: `${imp.asset_name || imp.asset_path}`,
                    asset_name: imp.asset_name,
                    asset_path: imp.asset_path,
                    line_number: imp.line_number,
                    worker_thread_id: workerId
                });
            });

            // Sort segments by start_time (should already be sorted, but ensure it)
            segments.sort((a, b) => {
                if (a.start_time !== b.start_time) {
                    return a.start_time - b.start_time;
                }
                // If start times are equal, sort by line number
                return (a.line_number || 0) - (b.line_number || 0);
            });

            // Group consecutive segments with no gap between them
            // A gap exists when next.start_time > previous.start_time + previous.duration_ms
            // Use small tolerance (1ms) to account for floating point precision
            const groupedSegments = [];
            let currentGroup = null;
            const GAP_TOLERANCE_MS = 10; // increased from 1ms to 10ms to allow slight gaps to merge

            segments.forEach((segment, index) => {
                if (currentGroup === null) {
                    // Start a new group
                    currentGroup = {
                        phase: 'WorkerImport',
                        start_time: segment.start_time,
                        duration_ms: segment.duration_ms,
                        color: segment.color,
                        category: segment.category,
                        description: segment.description,
                        asset_name: segment.asset_name,
                        asset_path: segment.asset_path,
                        line_number: segment.line_number,
                        worker_thread_id: workerId,
                        operation_count: 1,
                        operations: [segment] // Track individual operations for details
                    };
                } else {
                    // Check if this segment continues the current group (no gap)
                    const groupEndTime = currentGroup.start_time + currentGroup.duration_ms;
                    const timeDiff = segment.start_time - groupEndTime;

                    // No gap if start time equals or is very close to group end time (within tolerance)
                    if (timeDiff >= 0 && timeDiff <= GAP_TOLERANCE_MS) {
                        // No gap - add to current group
                        currentGroup.duration_ms += segment.duration_ms;
                        currentGroup.operation_count++;
                        currentGroup.operations.push(segment);

                        // Update description to indicate grouping
                        const firstDesc = currentGroup.operations[0].description || currentGroup.operations[0].asset_name || 'Operation';
                        currentGroup.description = `${firstDesc} (+${currentGroup.operation_count - 1} more)`;
                    } else {
                        // Gap exists - finish current group and start new one
                        groupedSegments.push(currentGroup);
                        currentGroup = {
                            phase: 'WorkerImport',
                            start_time: segment.start_time,
                            duration_ms: segment.duration_ms,
                            color: segment.color,
                            category: segment.category,
                            description: segment.description,
                            asset_name: segment.asset_name,
                            asset_path: segment.asset_path,
                            line_number: segment.line_number,
                            worker_thread_id: workerId,
                            operation_count: 1,
                            operations: [segment]
                        };
                    }
                }

                // Finish group if this is the last segment
                if (index === segments.length - 1) {
                    groupedSegments.push(currentGroup);
                }
            });

            // Add worker phase blocks for this worker thread
            const phaseBlocks = [];
            const workerPhasesForThread = workerPhases.filter(p => p.worker_thread_id === parseInt(workerId));

            workerPhasesForThread.forEach(phase => {
                let startTime = 0;
                const durationMs = phase.duration_ms || 0;

                if (phase.start_timestamp && firstTimestamp) {
                    const phaseStartTime = new Date(phase.start_timestamp).getTime();
                    startTime = phaseStartTime - startTimeOffset;
                } else {
                    // Fallback: use line number if no timestamp
                    startTime = 0;
                }

                phaseBlocks.push({
                    phase: 'WorkerPhase',
                    start_time: startTime,
                    duration_ms: durationMs,
                    color: 'rgba(255, 152, 0, 0.3)', // Semi-transparent orange overlay
                    description: `Worker Phase: ${phase.import_count} imports`,
                    import_count: phase.import_count,
                    line_number: phase.start_line_number,
                    worker_thread_id: workerId,
                    is_phase_block: true // Flag to identify phase blocks for rendering
                });
            });

            workerTimelines[workerId] = {
                worker_id: workerId,
                segments: groupedSegments,
                phase_blocks: phaseBlocks, // Add phase blocks separately
                total_operations: segments.length // Total individual operations
            };
        });

        return workerTimelines;
    }

    /**
     * Get color for worker thread based on ID
     * @private
     */
    _getWorkerColor(workerId) {
        const colors = [
            '#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8',
            '#F7DC6F', '#BB8FCE', '#85C1E2', '#F8B739', '#52BE80'
        ];
        return colors[parseInt(workerId) % colors.length];
    }

    /**
     * Helper to finish a chunk and add it to importChunks
     */
    _finishChunk(currentChunk, importChunks, calculateChunkTime, calculateActualImportTime) {
        const chunkStartTimestamp = currentChunk[0].start_timestamp;
        const chunkEndTimestamp = currentChunk[currentChunk.length - 1].end_timestamp;
        const chunkTime = calculateChunkTime(currentChunk); // For timeline visualization
        const actualImportTime = calculateActualImportTime(currentChunk); // For statistics
        const chunkCategory = currentChunk[0].category || 'Other';

        // Debug: Log texture chunks specifically
        if (chunkCategory === 'Textures' && chunkTime === 0) {
            console.warn('[Timeline] Texture chunk with zero time:', {
                count: currentChunk.length,
                start_line: currentChunk[0].line_number,
                end_line: currentChunk[currentChunk.length - 1].line_number,
                actual_import_time_ms: actualImportTime,
                events: currentChunk.slice(0, 3).map(e => ({
                    time_ms: e.time_ms,
                    has_timestamp: !!(e.start_timestamp || e.end_timestamp)
                }))
            });
        }

        importChunks.push({
            start_line: currentChunk[0].line_number,
            end_line: currentChunk[currentChunk.length - 1].line_number,
            time_ms: chunkTime, // Wall time for timeline visualization
            actual_import_time_ms: actualImportTime, // Actual work time for statistics
            count: currentChunk.length,
            category: chunkCategory,
            start_timestamp: chunkStartTimestamp,
            end_timestamp: chunkEndTimestamp
        });
    }
}

// Export for use in other modules
window.TimelineBuilder = TimelineBuilder;

